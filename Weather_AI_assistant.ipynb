{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nj-l6TqdN7ZP"
   },
   "source": [
    "#### Make sure that you read your API Key from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('apikey.txt', 'r') as f:\n",
    "    openai.api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('weatherapikey.txt', 'r') as f:\n",
    "    WEATHER_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6fd4u4GNnud",
    "tags": []
   },
   "source": [
    "## **Project Description:**\n",
    "Create an AI assistant that will answer \"What's the temperature outside now\" or \"What's the temperature in Tokio now\" type of questions (location can be any big city). Ask for the location of the user if the location is not in the question. Use OpenAI APIs, [openweathermap](http://api.openweathermap.org/data/2.5/weather) API(it is free), and function calling.\n",
    "\n",
    "**Project Steps:**\n",
    "* Step 1: Use OpenAI Chat Completions API to get the location of the user if it is not given. If it is given, use function calling for getting weather api parameter(s).\n",
    "* Step 2: Call weather api for the given location.\n",
    "* Step 3: Call Chat Completions API again for processing the response of weather api. Make it to provide short answer like this: \"The temperature in Yerevan is -1.91 degrees Celsius\".\n",
    "* Step 4: Call Chat Completions API again to translate the output of Step 3 into Armenian.\n",
    "* Step 5: Use OpenAI Text to Speech API to create an audio version (mp3) of the output of Step 4.\n",
    "* Step 6: Use one of OpenAIs APIs to create an image based on the output of Step 3 (text to image).\n",
    "* Step 7: Use one of OpenAIs APIs to extract text (if any) from the output of Step 6\n",
    "* Step 8: Create a Chainlit app that will answer the questions mentioned at the beginning and will output the outputs of Steps 3, 4, 5, 6, and 7.\n",
    "\n",
    "Useful links:\n",
    "* [Chainlit App Creation](https://docs.chainlit.io/get-started/pure-python])\n",
    "* [Text, Image, Audio and Video response with Chainlit](https://docs.chainlit.io/api-reference/elements/text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import warnings\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Use OpenAI Chat Completions API to get the location of the user if it is not given. If it is given, use function\n",
    "# calling for getting weather api parameter(s).\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=\"gpt-4-1106-preview\"):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key, \n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if tools is not None:\n",
    "        json_data.update({\"tools\": tools})\n",
    "    if tool_choice is not None:\n",
    "        json_data.update({\"tool_choice\": tool_choice})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        response_json = response.json()\n",
    "        # Extracting the translated text from the response\n",
    "        translated_text = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return translated_text\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_location(input_text):\n",
    "    # Define a prompt that instructs the AI to extract the city name\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"Extract the city name from the user's input.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{input_text}\"}\n",
    "    ]\n",
    "\n",
    "    # Use the chat_completion_request function to send the prompt\n",
    "    location = chat_completion_request(prompt)\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: Call weather api for the given location.\n",
    "# Step 3: Call Chat Completions API again for processing the response of weather api. Make it to provide short answer like this:\n",
    "# \"The temperature in Yerevan is -1.91 degrees Celsius\".\n",
    "    \n",
    "def get_weather(location):\n",
    "    url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\n",
    "        \"q\": location,\n",
    "        \"appid\": WEATHER_API_KEY,\n",
    "        \"units\": \"metric\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        weather_data = response.json()\n",
    "        temperature = weather_data['main']['temp']\n",
    "\n",
    "        weather_message = [\n",
    "            {\"role\": \"system\", \"content\": \"You are weather assistant\"},\n",
    "            {\"role\": \"user\", \"content\": f\"In location {location} the current temperature is {temperature} degrees Celsius. Provide short answer stating this fact to user.\"},\n",
    "        ]\n",
    "\n",
    "        return chat_completion_request(weather_message, model=\"gpt-4-1106-preview\")\n",
    "    else:\n",
    "        print(f\"Error fetching weather data: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: Call Chat Completions API again to translate the output of Step 3 into Armenian.\n",
    "def translate_text(text, target_language=\"Armenian\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a highly intelligent translator.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Translate the given English text to {target_language}: {text}\"}\n",
    "    ]\n",
    "    translated_text = chat_completion_request(messages,tools=tools)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 5: Use OpenAI Text to Speech API to create an audio version (mp3) of the output of Step 4.\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "def text_to_audio(text, file_path=\"translation.mp3\"):\n",
    "    try:\n",
    "        response = openai.audio.speech.create(\n",
    "            model=\"tts-1-hd\",\n",
    "            voice=\"alloy\",\n",
    "            input=text\n",
    "        )\n",
    "        response.stream_to_file(file_path)\n",
    "        print(f\"Audio file created successfully at: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create audio file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 6: Use one of OpenAIs APIs to create an image based on the output of Step 3 (text to image).\n",
    "def text_to_image(city, weather):\n",
    "    response = openai.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=f\"create nice image of {city} that has {weather} weather, dont include any text\",\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"hd\",\n",
    "        n=1\n",
    "    )\n",
    "    return response.data[0].url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 7: Use one of OpenAIs APIs to extract text (if any) from the output of Step 6.\n",
    "def image_to_text(image_url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=[\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "              {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "              {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                  \"url\": image_url,\n",
    "                  \"detail\": \"high\"\n",
    "                },\n",
    "              },\n",
    "            ],\n",
    "          }\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted location: New York\n",
      "The current temperature in New York is 8.47 degrees Celsius.\n",
      "Հիմանու Ջերմաստիճանն Նյու Յորքում է 8.47 աստիճան Ցելսիուս։\n",
      "Audio file created successfully at: weather_audio.mp3\n",
      "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-ZzOlacmiAFcP64tkl2KTUBHK/user-4YdabjCsnllhavGbB8gZlXfu/img-lfjTLYeAfwHJHwZBETqI9aIj.png?st=2024-02-11T18%3A59%3A59Z&se=2024-02-11T20%3A59%3A59Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-02-11T15%3A19%3A31Z&ske=2024-02-12T15%3A19%3A31Z&sks=b&skv=2021-08-06&sig=tPQWPFQyNRkysz%2BAXV9%2BSOA6vX/uk6dJ2vuw2g7Nax0%3D\n",
      "Extracted text from image: This is a digital artwork or illustration depicting an urban winter scene. The image seems highly stylized and gives an impressionistic view of a city. You see a street lined with tall buildings. There is a mix of architectural styles, including modern skyscrapers and older, historic-looking buildings. The Chrysler Building, a recognizable New York City landmark, is prominently featured which suggests the city might be inspired by New York.\n",
      "\n",
      "The ground is covered in snow, and many bare trees suggest it's wintertime. People are walking along the sidewalks and in the street, bundled up in winter clothing. The presence of pedestrians gives the scene a lively, bustling atmosphere.\n",
      "\n",
      "There's a bus with the word \"MAIN\" displayed as its destination near the right foreground of the picture, contributing to the urban feel. The bright sun in the background casts a warm glow over the scene, and steam or smoke is rising from several chimneys, which adds to the winter atmosphere. Birds can be seen flying in the sky above the buildings, further enlivening the cityscape. The overall effect is quite picturesque and serene, despite the busyness implied by the crowded street.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Example user input\n",
    "    user_input = \"What's the temperature in New York now\"\n",
    "\n",
    "    # STEP 1\n",
    "    location = get_location(user_input)\n",
    "    if location:\n",
    "        print(f\"Extracted location: {location}\")\n",
    "\n",
    "        # STEP 2, 3\n",
    "        weather = get_weather(location)\n",
    "        if weather:\n",
    "            print(weather)\n",
    "\n",
    "            # STEP 4\n",
    "            translated_response = translate_text(weather)\n",
    "            if translated_response:\n",
    "                print(translated_response)\n",
    "                \n",
    "                # STEP 5\n",
    "                text_to_audio(translated_response, \"weather_audio.mp3\")\n",
    "            else:\n",
    "                print(\"Translation failed.\")\n",
    "\n",
    "            # STEP 6\n",
    "            image_url = text_to_image(location, weather)\n",
    "            print(f'Image URL: {image_url}')\n",
    "            \n",
    "            # STEP 7\n",
    "            extracted_text = image_to_text(image_url)\n",
    "            print(f'Extracted text from image: {extracted_text}')\n",
    "\n",
    "        else:\n",
    "            print(\"Failed to fetch weather data.\")\n",
    "    else:\n",
    "        print(\"Failed to extract location from user input.\")\n",
    "\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 8: Create a Chainlit app that will answer the questions mentioned at the beginning and will output the\n",
    "# outputs of Steps 3, 4, 5, 6, and 7.\n",
    "\n",
    "# Application code is in app.py file (below is the code)\n",
    "\n",
    "# import chainlit as cl\n",
    "\n",
    "# # Define the function to handle incoming messages\n",
    "# @cl.on_message\n",
    "# async def main(message: cl.Message):\n",
    "    \n",
    "#     user_input = message.content\n",
    "\n",
    "#     # STEP 1: Extract location from user input\n",
    "#     location = get_location(user_input)\n",
    "#     if location:\n",
    "#         # STEP 2, 3: Get weather information for the extracted location\n",
    "#         weather = get_weather(location)\n",
    "#         if weather:\n",
    "#             # Print the original weather response\n",
    "#             await cl.Message(content=weather).send()\n",
    "\n",
    "#             # STEP 4: Translate the weather response\n",
    "#             translated_response = translate_text(weather)\n",
    "#             if translated_response:\n",
    "#                 # Print the translated response\n",
    "#                 await cl.Message(content=translated_response).send()\n",
    "\n",
    "#                 # STEP 5: Convert translated text to audio\n",
    "#                 text_to_audio(translated_response, \"weather_audio.mp3\")\n",
    "\n",
    "#                 # STEP 6: Generate an image based on location and weather\n",
    "#                 image_url = text_to_image(location, weather)\n",
    "#                 # Print the image URL\n",
    "#                 await cl.Message(content=f'Image URL: {image_url}').send()\n",
    "\n",
    "#                 # STEP 7: Extract text from the generated image\n",
    "#                 extracted_text = image_to_text(image_url)\n",
    "#                 # Print the extracted text from the image\n",
    "#                 await cl.Message(content=f'Extracted text from image: {extracted_text}').send()\n",
    "#             else:\n",
    "#                 await cl.Message(content=\"Translation failed.\").send()\n",
    "#         else:\n",
    "#             await cl.Message(content=\"Failed to fetch weather data.\").send()\n",
    "#     else:\n",
    "#         await cl.Message(content=\"Failed to extract location from user input.\").send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJGFkzMldY0p"
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
